{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.RecordBatch\n",
      "n_legs: int64\n",
      "animals: string\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'n_legs': [2, 4, 5, 100],\n",
    "                   'animals': [\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"]})\n",
    "table = pa.Table.from_pandas(df)\n",
    "print(table.to_batches()[0])\n",
    "\n",
    "\n",
    "recBatchOutSchema = table.schema\n",
    "recBatchOutColumns = table.column_names\n",
    "recBatchOutDict = {}\n",
    "for name in recBatchOutColumns:\n",
    "    recBatchOutDict[name] = []\n",
    "emptyRecBatchOut = pa.RecordBatch.from_pydict(\n",
    "    mapping=recBatchOutDict, schema=recBatchOutSchema)\n",
    "\n",
    "print(emptyRecBatchOut.column(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "# 定义两个RecordBatch对象\n",
    "# 假设我们有两个包含相同列的RecordBatch\n",
    "\n",
    "# 第一个RecordBatch的数据\n",
    "data1 = [\n",
    "    pa.array([1, 2, 3]),\n",
    "    pa.array(['a', 'b', 'c'])\n",
    "]\n",
    "\n",
    "# 第一个RecordBatch\n",
    "record_batch1 = pa.RecordBatch.from_arrays(data1, names=['id', 'letter'])\n",
    "\n",
    "# 第二个RecordBatch的数据\n",
    "data2 = [\n",
    "    pa.array([4, 5, 6]),\n",
    "    pa.array(['d', 'e', 'f'])\n",
    "]\n",
    "\n",
    "# 第二个RecordBatch\n",
    "record_batch2 = pa.RecordBatch.from_arrays(data2, names=['id', 'letter'])\n",
    "\n",
    "# 假设您有一个RecordBatch列表\n",
    "record_batch_list = [record_batch1, record_batch2]\n",
    "\n",
    "# 将所有RecordBatch合并成一个Table\n",
    "table = pa.Table.from_batches(record_batch_list)\n",
    "\n",
    "# 将Table转换回一个单一的RecordBatch\n",
    "# 注意：这个操作假设所有RecordBatch的总大小可以放入内存\n",
    "combined_record_batch = pa.RecordBatch.from_pandas(table.to_pandas())\n",
    "\n",
    "# 现在 combined_record_batch 是一个包含所有数据的单一RecordBatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100it [00:10,  9.56it/s]                       \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 例如，一个简单的循环\n",
    "for i in tqdm(range(100),desc=\"test\",total=10):\n",
    "    # 模拟你的任务\n",
    "    time.sleep(0.1)  # 模拟任务需要的时间\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/resource_tracker.py:104: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460.234375, 460.859375, 470.140625, 479.3125, 482.9375, 492.515625, 502.140625, 511.9375, 521.75, 531.53125, 541.296875, 550.984375, 560.671875, 570.140625, 579.546875, 589.28125, 598.96875, 608.734375, 618.5625, 628.3125, 638.109375, 647.859375, 657.703125, 667.46875, 677.15625, 687.015625, 696.828125, 598.515625, 608.3125, 618.125, 627.953125, 637.78125, 647.625, 657.53125, 667.21875, 676.84375, 686.65625, 696.40625, 706.1875, 715.984375, 725.796875, 735.546875, 745.328125, 755.125, 764.921875, 774.71875, 784.484375, 794.359375, 803.859375, 813.65625, 823.5, 833.3125, 843.03125, 852.5625, 862.34375, 872.296875, 882.109375, 891.984375, 901.828125, 911.609375, 921.390625, 931.125, 940.96875, 950.8125, 960.59375, 970.390625, 980.28125, 990.0625, 999.859375, 1009.625, 1019.46875, 1029.21875, 1038.90625, 1048.515625, 1058.296875, 1068.046875, 1077.78125, 1087.46875, 1097.25, 1067.984375, 1077.734375, 1087.515625, 1097.296875, 1107.078125, 1116.796875, 1126.546875, 1088.671875, 1098.4375, 1108.21875, 1118.125, 1127.9375, 1085.984375, 1095.765625, 1105.578125, 1115.375, 1125.1875, 1135.03125, 1144.84375, 1154.671875, 1105.84375, 1115.625, 1125.46875, 1064.171875, 1073.609375, 1083.359375, 1093.171875, 1102.96875, 1112.734375, 1077.203125, 1086.953125, 1096.609375, 1106.375, 1116.1875, 1072.21875, 1081.9375, 1091.671875, 1101.390625, 1111.09375, 973.484375, 983.234375, 992.9375, 1002.578125, 1012.28125, 960.671875, 909.515625, 919.296875, 929.046875, 938.765625, 948.5, 958.21875, 967.9375, 977.671875, 987.4375, 997.09375, 972.0, 981.75, 991.53125, 961.578125, 967.359375, 977.0625, 986.84375, 996.59375, 1006.34375, 1016.09375, 1016.265625, 1026.015625, 1035.71875, 1045.4375, 1055.1875, 1042.171875, 1051.890625, 1061.671875, 1056.0625, 1065.609375, 1075.296875, 1076.640625, 1086.359375, 1096.046875, 1105.796875, 1095.8125, 1163.421875, 1194.359375, 1226.984375, 1254.34375, 1319.640625, 1340.375, 1348.1875, 1356.046875, 1422.734375, 1440.78125, 1494.8125, 1557.890625, 1619.890625, 1681.390625, 1743.25, 1801.765625, 1861.8125, 1923.84375, 1985.578125, 2026.234375, 2034.640625, 2047.0, 2079.078125, 2092.875, 2112.90625, 1628.921875, 1679.515625, 1726.34375, 1755.578125, 1786.75, 1917.5625, 2261.390625, 2166.046875, 2265.828125, 2332.90625, 2310.578125, 2339.484375, 2291.5, 2322.640625, 2396.515625, 2555.390625, 2697.0, 2798.40625, 2788.703125, 2785.390625, 2704.765625, 2734.484375, 2712.84375, 2678.390625, 1594.96875]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "array1 = pa.array(np.arange(1, 100_000_000 + 1, dtype=np.int64))\n",
    "array2 = pa.array([2] * 100_000_000, type=pa.int64())\n",
    "\n",
    "table = pa.RecordBatch.from_arrays([array1, array2], names=['a', 'b'])\n",
    "\n",
    "def test():\n",
    "    column_name = 'a'\n",
    "    n = 3  # 分割成3个RecordBatch\n",
    "\n",
    "    # 获取列值\n",
    "    column_values = table.column(column_name)\n",
    "\n",
    "    # 计算哈希值并进行模运算\n",
    "    hash_mod_n = np.array([hash(value.as_py()) % n for value in column_values])\n",
    "\n",
    "    # 初始化一个列表来存储分割后的 RecordBatches\n",
    "    record_batches = [table.filter(pa.array(hash_mod_n == i)) for i in range(n)]\n",
    "\n",
    "\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "mem_usage = memory_usage(test)\n",
    "\n",
    "print(mem_usage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
