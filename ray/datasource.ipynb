{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 16:25:59,245\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:26:08,306 E 61600 11602863] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-03-26_16-25-56_370993_61542 is over 95% full, available space: 11956224000; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:26:18,394 E 61600 11602863] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-03-26_16-25-56_370993_61542 is over 95% full, available space: 11955494912; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:26:28,479 E 61600 11602863] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-03-26_16-25-56_370993_61542 is over 95% full, available space: 11955015680; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:26:38,569 E 61600 11602863] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-03-26_16-25-56_370993_61542 is over 95% full, available space: 11954393088; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:26:48,659 E 61600 11602863] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-03-26_16-25-56_370993_61542 is over 95% full, available space: 11953561600; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:26:58,742 E 61600 11602863] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-03-26_16-25-56_370993_61542 is over 95% full, available space: 11952553984; capacity: 494384795648. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-03-26 16:27:08,830 E 61600 11602863] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-03-26_16-25-56_370993_61542 is over 95% full, available space: 11954327552; capacity: 494384795648. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.ipc as ipc\n",
    "import numpy as np\n",
    "import ray\n",
    "\n",
    "ray.init()\n",
    "\n",
    "test_dir = \"./tes\"\n",
    "\n",
    "paths = []\n",
    "\n",
    "for i in range(10):\n",
    "    data = [\n",
    "        pa.array(np.arange(0, i+1, dtype=np.int64)),\n",
    "        pa.array([i] * (i+1), type=pa.int64())\n",
    "    ]\n",
    "    batch = pa.RecordBatch.from_arrays(data, ['numbers', 'strings'])\n",
    "\n",
    "    path = test_dir+\"/\"+str(i)\n",
    "    paths.append(path)\n",
    "    # Serialize RecordBatch to a file\n",
    "    with pa.OSFile(path, 'wb') as sink:\n",
    "        with ipc.new_stream(sink, batch.schema) as writer:\n",
    "            writer.write_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.data.datasource import Datasource, ReadTask\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.ipc as ipc\n",
    "import numpy as np\n",
    "from ray.data.block import BlockMetadata\n",
    "from typing import Iterable\n",
    "from ray.data.block import Block\n",
    "\n",
    "class ReadArrowFilesDatasource(Datasource):\n",
    "    def prepare_read(self, parallelism: int, files):\n",
    "        def read_file(files) -> Iterable[Block]:\n",
    "            for file in files:\n",
    "                with pa.memory_map(file, 'rb') as source:\n",
    "                    with ipc.open_stream(source) as reader:\n",
    "                        tbl = pa.Table.from_batches([b for b in reader])\n",
    "                        print(tbl.to_pandas())\n",
    "                        yield tbl\n",
    "\n",
    "        file_batches = np.array_split(files, np.ceil(len(files) / parallelism))\n",
    "\n",
    "        meta = BlockMetadata(\n",
    "            num_rows=None,\n",
    "            size_bytes=None,\n",
    "            schema=None,\n",
    "            input_files=None,\n",
    "            exec_stats=None,\n",
    "        )\n",
    "        read_tasks = [\n",
    "            ReadTask(lambda p=file_batch: read_file(p), meta)\n",
    "            for file_batch in file_batches\n",
    "        ]\n",
    "        return read_tasks\n",
    "\n",
    "\n",
    "\n",
    "# 创建Dataset\n",
    "custom_datasource = ReadArrowFilesDatasource()\n",
    "\n",
    "dataset = ray.data.read_datasource(custom_datasource, files=paths)\n",
    "dataset._lazy = False\n",
    "# 当你调用 to_arrow_refs 时，每个ObjectRef将对应每个文件中的内容\n",
    "arrow_refs = dataset.to_arrow_refs()\n",
    "\n",
    "\n",
    "print(len(arrow_refs))\n",
    "\n",
    "# for ref in arrow_refs:\n",
    "#     print(ray.get(ref).to_pandas())\n",
    "#     print(\"------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.schema())\n",
    "\n",
    "\n",
    "print(dir(dataset.schema()),type(dataset.schema()))\n",
    "for field in dataset.schema().types:\n",
    "    print(field,type(field))\n",
    "print(dataset.schema().base_schema,type(dataset.schema().base_schema))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
