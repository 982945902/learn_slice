llm:
  # provider: ollama
  # config:
  #   model: 'llama2'
  #   temperature: 0.5
  #   top_p: 1
  #   stream: true
  #   base_url: 'http://localhost:11434'
  provider: jina
  config:
    temperature: 0.5
    max_tokens: 1000
    top_p: 1
    stream: false
embedder:
  provider: huggingface
  config:
    model: 'sentence-transformers/all-mpnet-base-v2'